{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650bfe85-487f-48a5-9e60-ddefb5ad9936",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    accuracy_score,\n",
    "    cohen_kappa_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from collections import Counter\n",
    "\n",
    "# Set environment settings\n",
    "print(\"Setting up environment...\")\n",
    "arcpy.env.workspace = r\"D:\\YAP\\RandomForest\"\n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "# Define paths\n",
    "print(\"Defining paths...\")\n",
    "input_raster = r\"D:\\YAP\\RandomTree\\Sentinel2_2017_TWD.tif\"\n",
    "reference_raster = os.path.join(r\"D:\\YAP\\RandomTree\", \"reference_raster.tif\")\n",
    "output_folder = r\"D:\\YAP\\RandomTree\"\n",
    "\n",
    "# Output paths\n",
    "accuracy_report_path = os.path.join(output_folder, \"accuracy_report_2017.txt\")\n",
    "csv_output_path = os.path.join(output_folder, \"accuracy_report_2017.csv\")\n",
    "heatmap_output_path = os.path.join(output_folder, \"confusion_matrix_heatmap_2017.png\")\n",
    "training_samples_shapefile = os.path.join(output_folder, \"training_samples_2017.shp\")\n",
    "testing_samples_shapefile = os.path.join(output_folder, \"testing_samples_2017.shp\")\n",
    "\n",
    "# Read raster data\n",
    "print(\"Reading raster data...\")\n",
    "raster = arcpy.RasterToNumPyArray(input_raster)\n",
    "raster_shape = raster.shape  # (bands, rows, columns)\n",
    "desc = arcpy.Describe(input_raster)\n",
    "lower_left = desc.extent.lowerLeft\n",
    "\n",
    "# Get cell size using arcpy.GetRasterProperties_management\n",
    "cell_width = float(\n",
    "    arcpy.GetRasterProperties_management(input_raster, \"CELLSIZEX\").getOutput(0)\n",
    ")\n",
    "cell_height = float(\n",
    "    arcpy.GetRasterProperties_management(input_raster, \"CELLSIZEY\").getOutput(0)\n",
    ")\n",
    "\n",
    "# Read the reference raster\n",
    "print(\"Reading reference raster...\")\n",
    "reference = arcpy.RasterToNumPyArray(reference_raster)\n",
    "\n",
    "# Function to generate samples from the raster and reference raster\n",
    "def generate_samples_from_raster(\n",
    "    raster_array, reference_array, num_samples_per_class, output_points_path\n",
    "):\n",
    "    print(\"Generating samples from raster and reference raster...\")\n",
    "    # Reshape raster data to 2D array (pixels x bands)\n",
    "    raster_2d = raster_array.reshape(raster_array.shape[0], -1).T\n",
    "    # Flatten reference raster labels\n",
    "    reference_flat = reference_array.ravel().astype(str)\n",
    "\n",
    "    # Get unique class labels\n",
    "    classes, counts = np.unique(reference_flat, return_counts=True)\n",
    "    print(\"Classes in reference raster:\", classes)\n",
    "\n",
    "    # Initialize lists to hold samples and labels\n",
    "    data_list = []\n",
    "    labels_list = []\n",
    "    x_coords = []\n",
    "    y_coords = []\n",
    "\n",
    "    for cls in classes:\n",
    "        if cls == \"nan\" or cls == \"\":\n",
    "            continue  # Skip invalid classes\n",
    "        # Get indices of pixels belonging to the current class\n",
    "        indices = np.where(reference_flat == cls)[0]\n",
    "        if len(indices) == 0:\n",
    "            continue\n",
    "        # Randomly select samples from the indices\n",
    "        np.random.shuffle(indices)\n",
    "        selected_indices = indices[:num_samples_per_class]\n",
    "\n",
    "        # Append the selected samples and labels\n",
    "        data_list.append(raster_2d[selected_indices])\n",
    "        labels_list.append(np.full(len(selected_indices), cls))\n",
    "\n",
    "        # Calculate coordinates for the selected indices\n",
    "        rows = selected_indices // raster_shape[2]\n",
    "        cols = selected_indices % raster_shape[2]\n",
    "        x = lower_left.X + cols * cell_width + cell_width / 2\n",
    "        y = lower_left.Y + rows * cell_height + cell_height / 2\n",
    "        x_coords.extend(x)\n",
    "        y_coords.extend(y)\n",
    "\n",
    "    # Combine data and labels\n",
    "    if data_list:\n",
    "        data = np.vstack(data_list)\n",
    "        labels = np.hstack(labels_list)\n",
    "        coords = np.column_stack((x_coords, y_coords))\n",
    "    else:\n",
    "        data = np.array([])\n",
    "        labels = np.array([])\n",
    "        coords = np.array([])\n",
    "\n",
    "    # Export samples to shapefile\n",
    "    if coords.size > 0:\n",
    "        print(f\"Exporting samples to shapefile: {output_points_path}\")\n",
    "        spatial_ref = desc.spatialReference\n",
    "\n",
    "        # Create a NumPy array with fields for coordinates and labels\n",
    "        samples_array = np.array(\n",
    "            list(zip(coords[:, 0], coords[:, 1], labels)),\n",
    "            dtype=[(\"X\", \"f8\"), (\"Y\", \"f8\"), (\"Label\", \"U50\")],\n",
    "        )\n",
    "\n",
    "        # Define the in-memory table path\n",
    "        in_memory_table = \"in_memory\\\\samples_table\"\n",
    "\n",
    "        # Check if the in-memory table exists and delete it\n",
    "        if arcpy.Exists(in_memory_table):\n",
    "            arcpy.Delete_management(in_memory_table)\n",
    "\n",
    "        # Convert NumPy array to a table\n",
    "        arcpy.da.NumPyArrayToTable(samples_array, in_memory_table)\n",
    "\n",
    "        # Create a point feature class from the table\n",
    "        arcpy.management.XYTableToPoint(\n",
    "            in_table=in_memory_table,\n",
    "            out_feature_class=output_points_path,\n",
    "            x_field=\"X\",\n",
    "            y_field=\"Y\",\n",
    "            coordinate_system=spatial_ref,\n",
    "        )\n",
    "\n",
    "        # Add and calculate the label field\n",
    "        if 'Label' not in [f.name for f in arcpy.ListFields(output_points_path)]:\n",
    "            arcpy.management.AddField(output_points_path, \"Label\", \"TEXT\")\n",
    "        arcpy.management.CalculateField(\n",
    "            output_points_path, \"Label\", \"!Label!\", \"PYTHON3\"\n",
    "        )\n",
    "\n",
    "        # Clean up in-memory table\n",
    "        arcpy.Delete_management(in_memory_table)\n",
    "    else:\n",
    "        print(\"No samples to export.\")\n",
    "\n",
    "    return data, labels, coords  # Return coords as well\n",
    "\n",
    "# Generate samples from raster\n",
    "training_data, training_labels, coords = generate_samples_from_raster(\n",
    "    raster,\n",
    "    reference,\n",
    "    num_samples_per_class=1000,  # Adjust as needed\n",
    "    output_points_path=training_samples_shapefile,\n",
    ")\n",
    "\n",
    "# Encode labels\n",
    "print(\"Encoding labels...\")\n",
    "le = LabelEncoder()\n",
    "labels_str = training_labels.astype(str)\n",
    "le.fit(labels_str)\n",
    "labels_encoded = le.transform(labels_str)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "print(\"Splitting data into training and testing sets...\")\n",
    "(\n",
    "    training_data,\n",
    "    testing_data,\n",
    "    training_labels_encoded,\n",
    "    testing_labels_encoded,\n",
    "    training_coords,\n",
    "    testing_coords,\n",
    "    training_labels_str,\n",
    "    testing_labels_str,\n",
    ") = train_test_split(\n",
    "    training_data,\n",
    "    labels_encoded,\n",
    "    coords,\n",
    "    labels_str,\n",
    "    test_size=0.2,\n",
    "    stratify=labels_encoded,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Export testing samples to shapefile\n",
    "def export_samples_to_shapefile(coords, labels, output_points_path):\n",
    "    print(f\"Exporting samples to shapefile: {output_points_path}\")\n",
    "    spatial_ref = desc.spatialReference\n",
    "\n",
    "    # Create a NumPy array with fields for coordinates and labels\n",
    "    samples_array = np.array(\n",
    "        list(zip(coords[:, 0], coords[:, 1], labels)),\n",
    "        dtype=[(\"X\", \"f8\"), (\"Y\", \"f8\"), (\"Label\", \"U50\")],\n",
    "    )\n",
    "\n",
    "    # Define the in-memory table path\n",
    "    in_memory_table = \"in_memory\\\\samples_table_test\"\n",
    "\n",
    "    # Check if the in-memory table exists and delete it\n",
    "    if arcpy.Exists(in_memory_table):\n",
    "        arcpy.Delete_management(in_memory_table)\n",
    "\n",
    "    # Convert NumPy array to a table\n",
    "    arcpy.da.NumPyArrayToTable(samples_array, in_memory_table)\n",
    "\n",
    "    # Create a point feature class from the table\n",
    "    arcpy.management.XYTableToPoint(\n",
    "        in_table=in_memory_table,\n",
    "        out_feature_class=output_points_path,\n",
    "        x_field=\"X\",\n",
    "        y_field=\"Y\",\n",
    "        coordinate_system=spatial_ref,\n",
    "    )\n",
    "\n",
    "    # Add and calculate the label field\n",
    "    if 'Label' not in [f.name for f in arcpy.ListFields(output_points_path)]:\n",
    "        arcpy.management.AddField(output_points_path, \"Label\", \"TEXT\")\n",
    "    arcpy.management.CalculateField(\n",
    "        output_points_path, \"Label\", \"!Label!\", \"PYTHON3\"\n",
    "    )\n",
    "\n",
    "    # Clean up in-memory table\n",
    "    arcpy.Delete_management(in_memory_table)\n",
    "\n",
    "# Export testing samples\n",
    "export_samples_to_shapefile(testing_coords, testing_labels_str, testing_samples_shapefile)\n",
    "\n",
    "# Scale features\n",
    "print(\"Scaling features...\")\n",
    "scaler = StandardScaler()\n",
    "training_data_scaled = scaler.fit_transform(training_data)\n",
    "testing_data_scaled = scaler.transform(testing_data)\n",
    "\n",
    "# Hyperparameter tuning using RandomizedSearchCV\n",
    "print(\"Starting hyperparameter tuning...\")\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'random_state': [0, 42, 100, 2021]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    class_weight='balanced',\n",
    "    n_jobs=-1  # Utilize all available cores\n",
    ")\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,  # Number of parameter settings that are sampled\n",
    "    scoring='accuracy',\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "random_search.fit(training_data_scaled, training_labels_encoded)\n",
    "best_params = random_search.best_params_\n",
    "print(f\"Best parameters found: {best_params}\")\n",
    "\n",
    "# Train Random Forest Classifier with best parameters\n",
    "print(\"Training Random Forest Classifier with best parameters...\")\n",
    "clf = RandomForestClassifier(\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    class_weight='balanced',\n",
    "    random_state=best_params['random_state'],\n",
    "    n_jobs=-1\n",
    ")\n",
    "clf.fit(training_data_scaled, training_labels_encoded)\n",
    "\n",
    "# Evaluate on testing data\n",
    "print(\"Evaluating model on testing data...\")\n",
    "predictions = clf.predict(testing_data_scaled)\n",
    "class_names = le.classes_\n",
    "conf_matrix = confusion_matrix(testing_labels_encoded, predictions)\n",
    "classification_rep = classification_report(\n",
    "    testing_labels_encoded,\n",
    "    predictions,\n",
    "    target_names=class_names,\n",
    "    zero_division=1\n",
    ")\n",
    "overall_accuracy = accuracy_score(testing_labels_encoded, predictions)\n",
    "kappa_value = cohen_kappa_score(testing_labels_encoded, predictions)\n",
    "print(f\"Overall Accuracy: {overall_accuracy:.2f}\")\n",
    "print(f\"Kappa Value: {kappa_value:.2f}\")\n",
    "\n",
    "# Save evaluation results\n",
    "print(\"Saving evaluation results...\")\n",
    "with open(accuracy_report_path, 'w') as f:\n",
    "    f.write(\"Evaluation on Testing Data:\\n\")\n",
    "    f.write(\"Confusion Matrix:\\n\")\n",
    "    f.write(str(conf_matrix))\n",
    "    f.write(\"\\n\\nClassification Report:\\n\")\n",
    "    f.write(classification_rep)\n",
    "    f.write(f\"\\nOverall Accuracy: {overall_accuracy:.2f}\\n\")\n",
    "    f.write(f\"Kappa Value: {kappa_value:.2f}\\n\")\n",
    "\n",
    "# Classify the entire raster using tile-based processing\n",
    "print(\"Classifying the entire raster using tile-based processing...\")\n",
    "\n",
    "# Define tile size (rows, columns)\n",
    "tile_size = (500, 500)  # Adjust as needed based on your system's memory capacity\n",
    "\n",
    "# Get raster dimensions\n",
    "n_bands, n_rows, n_cols = raster_shape\n",
    "\n",
    "# Initialize an empty array to store the classified result\n",
    "classified = np.zeros((n_rows, n_cols), dtype=np.float32)\n",
    "\n",
    "# Loop over tiles\n",
    "for row_start in range(0, n_rows, tile_size[0]):\n",
    "    row_end = min(row_start + tile_size[0], n_rows)\n",
    "    for col_start in range(0, n_cols, tile_size[1]):\n",
    "        col_end = min(col_start + tile_size[1], n_cols)\n",
    "        print(f\"Processing tile: Rows {row_start}-{row_end}, Columns {col_start}-{col_end}\")\n",
    "\n",
    "        # Extract tile data\n",
    "        tile_data = raster[:, row_start:row_end, col_start:col_end]\n",
    "        tile_shape = tile_data.shape  # (bands, tile_rows, tile_cols)\n",
    "\n",
    "        # Reshape tile data to 2D array (pixels x bands)\n",
    "        tile_data_2d = tile_data.reshape(tile_shape[0], -1).T\n",
    "\n",
    "        # Scale tile data\n",
    "        tile_data_scaled = scaler.transform(tile_data_2d)\n",
    "\n",
    "        # Predict classes for the tile\n",
    "        tile_predictions = clf.predict(tile_data_scaled)\n",
    "\n",
    "        # Reshape predictions back to tile shape and place in the classified array\n",
    "        tile_predictions_2d = tile_predictions.reshape((row_end - row_start), (col_end - col_start))\n",
    "        classified[row_start:row_end, col_start:col_end] = tile_predictions_2d.astype(np.float32)\n",
    "\n",
    "# Save classified raster\n",
    "print(\"Saving classified raster...\")\n",
    "output_raster_path = os.path.join(output_folder, \"classified_image_2017.tif\")\n",
    "classified_raster = arcpy.NumPyArrayToRaster(classified, lower_left, cell_width, cell_height)\n",
    "classified_raster.save(output_raster_path)\n",
    "\n",
    "# Read the classified raster and reference raster\n",
    "print(\"Reading classified raster and reference raster...\")\n",
    "classified_raster_array = arcpy.RasterToNumPyArray(output_raster_path)\n",
    "reference_flat = reference.ravel().astype(str)\n",
    "classified_flat = classified_raster_array.ravel()\n",
    "\n",
    "# Convert classified labels to original class names\n",
    "predicted_class_names = le.inverse_transform(classified_flat.astype(int))\n",
    "\n",
    "# Map predicted labels to the same label encoding as reference labels\n",
    "le_ref = LabelEncoder()\n",
    "all_labels = np.concatenate((reference_flat, predicted_class_names))\n",
    "le_ref.fit(all_labels)\n",
    "reference_encoded = le_ref.transform(reference_flat)\n",
    "predicted_encoded = le_ref.transform(predicted_class_names)\n",
    "\n",
    "# Evaluate classification over the entire raster\n",
    "print(\"Evaluating classification over the entire raster...\")\n",
    "overall_accuracy_full = accuracy_score(reference_encoded, predicted_encoded)\n",
    "kappa_value_full = cohen_kappa_score(reference_encoded, predicted_encoded)\n",
    "print(f\"Overall Accuracy (full raster): {overall_accuracy_full:.2f}\")\n",
    "print(f\"Kappa Value (full raster): {kappa_value_full:.2f}\")\n",
    "\n",
    "# Append results to the accuracy report\n",
    "with open(accuracy_report_path, 'a') as f:\n",
    "    f.write(\"\\n\\nEvaluation on Entire Raster:\\n\")\n",
    "    f.write(f\"\\nOverall Accuracy: {overall_accuracy_full:.2f}\\n\")\n",
    "    f.write(f\"Kappa Value: {kappa_value_full:.2f}\\n\")\n",
    "\n",
    "# Calculate area for each class\n",
    "print(\"Calculating area for each class...\")\n",
    "cell_area_sqm = cell_width * cell_height\n",
    "cell_area_sqkm = cell_area_sqm / 1e6  # Convert cell area to square kilometers\n",
    "\n",
    "# Create DataFrames\n",
    "reference_df = pd.DataFrame({'Class': reference_flat})\n",
    "classified_df = pd.DataFrame({'Class': predicted_class_names})\n",
    "\n",
    "# Calculate pixel counts\n",
    "reference_counts = reference_df['Class'].value_counts()\n",
    "classified_counts = classified_df['Class'].value_counts()\n",
    "\n",
    "# Compute areas\n",
    "reference_areas = (reference_counts * cell_area_sqkm).sort_index()\n",
    "classified_areas = (classified_counts * cell_area_sqkm).sort_index()\n",
    "\n",
    "# Combine into a DataFrame\n",
    "area_comparison = pd.DataFrame({\n",
    "    'Reference Area (sq km)': reference_areas,\n",
    "    'Classified Area (sq km)': classified_areas\n",
    "}).fillna(0)\n",
    "\n",
    "# Calculate differences\n",
    "area_comparison['Difference (sq km)'] = area_comparison['Classified Area (sq km)'] - area_comparison['Reference Area (sq km)']\n",
    "area_comparison['% Difference'] = (area_comparison['Difference (sq km)'] / area_comparison['Reference Area (sq km)']) * 100\n",
    "\n",
    "# Save the area comparison\n",
    "area_comparison_path = os.path.join(output_folder, 'area_comparison_2017.csv')\n",
    "area_comparison.to_csv(area_comparison_path, index_label='Class')\n",
    "print(f\"Area comparison saved to {area_comparison_path}\")\n",
    "\n",
    "# Plot and save the confusion matrix\n",
    "print(\"Plotting confusion matrix...\")\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(\n",
    "    conf_matrix,\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=class_names,\n",
    "    yticklabels=class_names\n",
    ")\n",
    "plt.title('Confusion Matrix for 2017')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.savefig(heatmap_output_path)\n",
    "plt.close()\n",
    "print(f\"Confusion matrix saved to {heatmap_output_path}\")\n",
    "\n",
    "print(\"\\nProcessing complete for the year 2017.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
